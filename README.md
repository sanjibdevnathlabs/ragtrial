# RAG Document Chat Application

A production-ready Retrieval-Augmented Generation (RAG) system with **ORM-like abstraction** for vector databases and embeddings. Switch providers with just configuration changes - **no code modifications needed**!

## ğŸ¯ Project Goals

Build a "Chat with your Documents" application with two parallel implementations:
1. **Simple RAG Chain** (LangChain) - Straightforward implementation
2. **Agent-Based RAG** (LangGraph) - Advanced with loops and conditional logic

Both connect to the same indexed data for easy comparison of approaches.

---

## âœ¨ Key Features

### ğŸ”„ Provider-Agnostic Architecture
- **ORM-like abstraction** similar to SQLAlchemy for databases
- **Zero code changes** to switch providers
- **16 provider combinations** supported out of the box

### ğŸ¨ Flexible Provider Support

**Embeddings (4 providers):**
- âœ… Google (text-embedding-004)
- âœ… OpenAI (text-embedding-3-small/large)
- âœ… HuggingFace (sentence-transformers) - **Local, no API key!**
- âœ… Anthropic (Voyage AI - voyage-2)

**Vectorstores (4 providers):**
- âœ… ChromaDB (local persistent storage)
- âœ… Pinecone (managed cloud service)
- âœ… Qdrant (open-source vector search)
- âœ… Weaviate (cloud-native vector database)

### ğŸ—ï¸ Production-Ready Infrastructure
- âœ… Type-safe configuration system (TOML-based)
- âœ… Structured JSON logging with `structlog`
- âœ… Zero string literals (trace codes for all events)
- âœ… Comprehensive error handling
- âœ… Batch processing for efficiency
- âœ… Complete test suite with pytest

---

## ğŸ“ Project Structure

```
ragtrial/
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ docs/                          # Documentation
â”‚   â””â”€â”€ PROVIDERS.md              # Provider switching guide
â”œâ”€â”€ examples/                      # Example scripts
â”‚   â”œâ”€â”€ demo_vectorstore.py       # Basic vectorstore usage
â”‚   â””â”€â”€ demo_provider_switching.py # Provider switching demo
â”œâ”€â”€ config/                        # Configuration system
â”‚   â””â”€â”€ __init__.py               # Singleton config loader
â”œâ”€â”€ embeddings/                    # Embeddings abstraction
â”‚   â”œâ”€â”€ base.py                   # EmbeddingsProtocol interface
â”‚   â”œâ”€â”€ factory.py                # Provider factory
â”‚   â””â”€â”€ implementations/          # Provider implementations
â”‚       â”œâ”€â”€ google.py
â”‚       â”œâ”€â”€ openai.py
â”‚       â”œâ”€â”€ huggingface.py
â”‚       â””â”€â”€ anthropic.py
â”œâ”€â”€ vectorstore/                   # Vectorstore abstraction
â”‚   â”œâ”€â”€ base.py                   # VectorStoreProtocol interface
â”‚   â”œâ”€â”€ factory.py                # Provider factory
â”‚   â””â”€â”€ implementations/          # Provider implementations
â”‚       â”œâ”€â”€ chroma.py
â”‚       â”œâ”€â”€ pinecone.py
â”‚       â”œâ”€â”€ qdrant.py
â”‚       â””â”€â”€ weaviate.py
â”œâ”€â”€ logger/                        # Logging system
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ setup.py                  # Structlog configuration
â”œâ”€â”€ trace/                         # Trace codes (zero string literals)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ codes.py                  # All trace codes
â”œâ”€â”€ ingestion/                     # Document ingestion pipeline
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ingest.py                 # Entry point script
â”œâ”€â”€ tests/                         # Test suite
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_config.py
â”‚   â””â”€â”€ test_logging.py
â””â”€â”€ environment/                   # Configuration files
    â””â”€â”€ default.toml              # Base configuration
```

---

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone <repo-url>
cd ragtrial

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Set API Key

```bash
export GEMINI_API_KEY="your-google-api-key"
```

**Get your free key:** https://aistudio.google.com/apikey

The default configuration uses:
- **Embeddings:** Google (text-embedding-004)
- **Vectorstore:** ChromaDB (local storage)

### 3. Run Database Setup

```bash
python scripts/setup_database.py
```

This automated script will:
- âœ… Check prerequisites
- âœ… Create storage directories
- âœ… Test embeddings connection
- âœ… Initialize ChromaDB
- âœ… Verify everything works

### 4. Run Examples

```bash
# Basic vectorstore demo
python examples/demo_vectorstore.py

# Provider switching demo
python examples/demo_provider_switching.py
```

**ğŸ“š Detailed Setup Guide:** See [docs/QUICKSTART.md](docs/QUICKSTART.md)

---

## ğŸ”„ Switching Providers

### Example: Change from Google to OpenAI

**1. Edit `environment/default.toml`:**
```toml
[embeddings]
provider = "openai"  # Changed from "google"
```

**2. Set API key:**
```bash
export OPENAI_API_KEY="your-openai-key"
```

**3. Run your application - NO CODE CHANGES!**
```bash
python examples/demo_provider_switching.py
```

### Example: Change from ChromaDB to Pinecone

**1. Edit `environment/default.toml`:**
```toml
[vectorstore]
provider = "pinecone"  # Changed from "chroma"
```

**2. Set API key:**
```bash
export PINECONE_API_KEY="your-pinecone-key"
```

**3. Run your application - Same code works!**

---

## ğŸ“š Documentation

- **[Quick Start Guide](docs/QUICKSTART.md)** - Step-by-step setup instructions
  - Database initialization
  - Troubleshooting
  - Alternative setups (Docker, local embeddings)
  - Configuration tips

- **[Provider Guide](docs/PROVIDERS.md)** - Complete guide to all supported providers
  - Installation instructions
  - Configuration examples
  - Provider comparison
  - Recommendations by use case

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run with verbose output
pytest tests/ -v

# Run specific test file
pytest tests/test_config.py
```

---

## ğŸ’¡ Usage Example

```python
from config import Config
from embeddings import create_embeddings
from vectorstore import create_vectorstore

# Load configuration
app_config = Config()

# Create providers (automatically picks from config)
embeddings = create_embeddings(app_config)
vectorstore = create_vectorstore(app_config, embeddings)

# Initialize
vectorstore.initialize()

# Add documents
vectorstore.add_documents(
    texts=["Document 1", "Document 2"],
    metadatas=[{"source": "a.pdf"}, {"source": "b.pdf"}]
)

# Query
results = vectorstore.query("What is RAG?", n_results=5)
```

**Same code works with ANY provider combination!**

---

## ğŸ› ï¸ Tech Stack

- **Language:** Python 3.13
- **Configuration:** TOML (type-safe, environment-aware)
- **Logging:** structlog (structured JSON logging)
- **Testing:** pytest
- **AI Framework:** LangChain / LangGraph (coming soon)
- **Vector DB:** ChromaDB / Pinecone / Qdrant / Weaviate
- **Embeddings:** Google / OpenAI / HuggingFace / Anthropic

---

## ğŸ¯ Roadmap

### âœ… Completed
- [x] Configuration system (TOML-based, type-safe)
- [x] Structured logging with trace codes
- [x] Embeddings abstraction (5 providers)
- [x] Vectorstore abstraction (4 providers)
- [x] Test organization with pytest
- [x] Provider switching examples
- [x] Comprehensive documentation

### ğŸš§ In Progress
- [ ] Document loaders (PDF, TXT, MD, DOCX, etc.)
- [ ] Text splitter implementation
- [ ] Document ingestion pipeline

### ğŸ“‹ Upcoming
- [ ] Simple RAG chain (LangChain)
- [ ] Agent-based RAG (LangGraph)
- [ ] Query interface
- [ ] Chat UI

---

## ğŸ“Š Provider Comparison

### Embeddings

| Provider | Dimension | API Key | Local/Cloud | Cost |
|----------|-----------|---------|-------------|------|
| Google | 768 | Yes | Cloud | Paid |
| OpenAI | 1536/3072 | Yes | Cloud | Paid |
| HuggingFace | 384 | No | **Local** | **Free** |
| Anthropic | 1024 | Yes | Cloud | Paid |

### Vectorstores

| Provider | Type | Setup | Scalability | Cost |
|----------|------|-------|-------------|------|
| ChromaDB | Local | Easy | Single machine | **Free** |
| Pinecone | Managed | Easy | Auto-scaling | Paid |
| Qdrant | Self-hosted/Cloud | Medium | High | Free/Paid |
| Weaviate | Self-hosted/Cloud | Medium | High | Free/Paid |

---

## ğŸ“ Recommendations

### For Development
- **Embeddings:** HuggingFace (free, runs locally)
- **Vectorstore:** ChromaDB (simple, local)

### For Production (Small Scale)
- **Embeddings:** Google or OpenAI (high quality)
- **Vectorstore:** Qdrant self-hosted (open-source)

### For Production (Large Scale)
- **Embeddings:** OpenAI or Google (reliable)
- **Vectorstore:** Pinecone or Weaviate Cloud (managed)

---

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Follow existing code patterns
2. Add tests for new features
3. Update documentation
4. Use trace codes (no string literals)

---

## ğŸ“„ License

[Add your license here]

---

## ğŸ”— Resources

- **Google AI:** https://ai.google.dev/docs/embeddings_guide
- **OpenAI:** https://platform.openai.com/docs/guides/embeddings
- **HuggingFace:** https://huggingface.co/sentence-transformers
- **ChromaDB:** https://docs.trychroma.com/
- **Pinecone:** https://docs.pinecone.io/
- **Qdrant:** https://qdrant.tech/documentation/
- **Weaviate:** https://weaviate.io/developers/weaviate

---

## ğŸ’¬ Questions?

See [docs/PROVIDERS.md](docs/PROVIDERS.md) for detailed provider information or run the examples to see the system in action!

**Happy RAG building! ğŸš€**

